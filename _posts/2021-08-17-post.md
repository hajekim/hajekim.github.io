---
title: "Install Kubeflow on Minikube - v20210817"
date: 2021-08-17 18:00:00 +0900
categories: 데이터 엔지니어링
tags: [Kubeflow, Minikube]
---
> ### Kubeflow 간단한 소개
![](https://upload.wikimedia.org/wikipedia/en/2/21/Kubeflow-logo.png)
머신러닝 워크플로우를 Kubernetes에서 손쉽게 이식하고 확장 가능하게 배포 및 운영을 목적으로 시작된 프로젝트입니다.
Google 내부에서 서비스에 사용하기 위해 개발된 서비스가 오픈소스 프로젝트로 릴리즈되어 시작하게 되었습니다.
국내는 [당근마켓](https://medium.com/daangn/kubeflow-%ED%8C%8C%EC%9D%B4%ED%94%84%EB%9D%BC%EC%9D%B8-%EC%9A%B4%EC%9A%A9%ED%95%98%EA%B8%B0-6c6d7bc98c30), [SOCAR](https://tech.socarcorp.kr/data/2020/03/10/ml-model-serving.html) 등 머신러닝/딥러닝이 응용되는 애플리케이션 서비스에서 널리 적용하고 사용하고 있는 ML Model Serving Tool입니다.

# Preface
Kubernetes 클러스터에 배포할 수 있습니다.
우선 이 문서에서는 Minikube에 간단하게 구성하도록 하겠습니다.
다음 포스팅에서 CentOS7에 K8s 클러스터를 구성하고 설치해보도록 하겠습니다.

## Pre-Installation Requirements
- kubectl
- kustomize
- passlib (pip3)
- py_bcrypt (pip3)
- Minikube

## Minikube Spec
제가 구성한 Minikube의 스펙입니다.
- 4 CPUs
- 8GB Memory
- 40GB Storage

macOS에서 Homebrew를 이용하여 손쉽게 설치할 수 있습니다.
CentOS나 Ubuntu에서도 패키지 매니저를 이용하여 손쉽게 설치해봅시다!
```bash
# Intsall Minikube
brew install minikube

# Start Minikube
minikube start --cpus 4 --memory 8096 --disk-size=40g
```


## Software Version

본 문서에서 사용된 K8s와 Kubeflow의 버전입니다.

- Kubeflow 1.3.0
- Kubernetes 1.21.2

과거 이 문서가 Kubeflow 1.15 버전을 사용할 때와는 좀 차이가 있습니다. **Kubeflow 1.3.0**에서는 버전 1.1x와 다르게 **[kustomize](https://kubernetes.io/ko/docs/tasks/manage-kubernetes-objects/kustomization/)**를 이용하여 설치하고 관리합니다.

Kustomize도 설치해보도록 합니다.
```bash
brew install kustomize
```

## Components of Kubeflow Manifests
아래의 컴포넌트가 포함되어 있습니다.
모두 설치할 수도 있고, 필요한 것만 개별로 설치할 수도 있습니다.
- TFJob Operator
- PyTorch Operator
- MPI Operator
- MXNet Operator
- XGBoost Operator
- Notebook Controller
- Tensorboard Controller
- Central Dashboard
- Profiles + KFAM
- PodDefaults Webhook
- Jupyter Web App
- Tensorboards Web App
- Volumes Web App
- Katib
- KFServing
- Kubeflow Pipelines
- Kubeflow Tekton Pipelines


# 설치하기

## 01. Kubeflow Manifest 준비

본 문서에서 설치에 사용될 바이너리를 준비합니다. [Kubeflow Manifest](https://github.com/kubeflow/manifests)를 사용할 것입니다.
여러 컴포넌트가 준비가 되어 있으므로, 손쉽게 설치가 가능합니다. 또한 불필요한 컴포넌트를 제외하고 필요한 컴포넌트만 메뉴얼하게 설치도 가능합니다.

우선, GitHub에서 클론으로 가져와 manifests 디렉토리에 들어가도록 합니다.

```bash
git clone https://github.com/kubeflow/manifests
cd manifests
```

## 02. Dex 수정하기
OIDC(OpenID Connect) Identity Service인 [Dex](https://github.com/dexidp/dex)를 통해 Kubernetes 사용자 인증을 관리합니다.
그런데 이슈가 하나 있습니다. Kubeflow 1.21 이후 버전에서는 Dex Manifest가 작동하지 않는 이슈가 있습니다.
해당 이슈: [Fix dex for Kubernetes 1.21 #1883](https://github.com/kubeflow/manifests/pull/1883)

해결 방법은 간단합니다.
문서를 보면 2가지 해결안을 제시(snap or yaml)하는데, snap을 이용하는 방법보다 쉬운 yaml 수정을 하도록 하겠습니다.

~~사실 macOS에서 snapd가 제대로 동작을 안하네요...~~

아래의 파일에서 31번째 줄에 추가해주세요.

```bash
vi manifests/common/dex/base/deployment.yaml
```
파일을 수정할 때 31번 라인에 아래의 NAMESPACE 설정을 추가해주도록 합니다.
띄어쓰기를 반드시 신경써서 넣어줍시다.

```bash
        env:
        - name: KUBERNETES_POD_NAMESPACE
          valueFrom:
            fieldRef:
              fieldPath: metadata.namespace
```
아래 이미지와 같이 보이면 됩니다.
![](https://images.velog.io/images/haje/post/3d8a1f1c-e9f0-4748-9565-3ea7189d5422/image.png)


## 02-1. Dex 사용자 수정하기 (생략 가능)
Kubeflow Manifests에 설정된 Default User와 Password는 아래와 같습니다.
- user@example.com
- 12341234

하지만 수정해보도록 하겠습니다.
**bcrypt**를 이용하여 비밀번호 Hash를 생성합니다.

```bash
python3 -c 'from passlib.hash import bcrypt; import getpass; print(bcrypt.using(rounds=12, ident="2y").hash(getpass.getpass()))'
```
![](https://images.velog.io/images/haje/post/1462d6b8-ef68-422e-a512-6f5dedde29b3/image.png)
마지막 라인의 Hash값을 복사하여 아래 파일에 입력합니다.

```bash
vi manifests/common/dex/base/config-map.yaml
```

21번 라인에 가서 User를 수정하고 Hash를 입력합니다.

```bash
 21     - email: hello@kubeflow.com
 22       hash: 요기에 입력
```


## 03. 설치하기
기본적인 세팅은 끝났습니다.
이제 간편하게 명령어 한 줄로 Kubeflow Manifests를 Minikube에 구성해보도록 하겠습니다.

```bash
while ! kustomize build example | kubectl apply -f -; do echo "Retrying to apply resources"; sleep 10; done
```


## 04. Pods 상태 확인
배포 요청한 컴포넌트들의 Pods가 정상적으로 떠있는지 확인해보도록 합니다.
```bash
kubectl get pods -A
NAMESPACE                   NAME                                                         READY   STATUS    RESTARTS   AGE
auth                        dex-5ddf47d88d-w5vbc                                         1/1     Running   1          164m
cert-manager                cert-manager-7dd5854bb4-ckkqz                                1/1     Running   0          3h3m
cert-manager                cert-manager-cainjector-64c949654c-n72pz                     1/1     Running   1          3h3m
cert-manager                cert-manager-webhook-6b57b9b886-h7htl                        1/1     Running   1          3h3m
istio-system                authservice-0                                                1/1     Running   0          174m
istio-system                cluster-local-gateway-75cb7c6c88-kw59j                       1/1     Running   0          174m
istio-system                istio-ingressgateway-79b665c95-8rsss                         1/1     Running   0          3h2m
istio-system                istiod-86457659bb-gqzng                                      1/1     Running   0          3h2m
knative-eventing            eventing-controller-575584745f-p8hhs                         1/1     Running   0          174m
knative-eventing            eventing-webhook-6d6f75c565-7zn7n                            1/1     Running   1          174m
knative-eventing            imc-controller-c8d86c869-qp5pj                               1/1     Running   0          174m
knative-eventing            imc-dispatcher-7bf75b8999-fndtx                              1/1     Running   0          174m
knative-eventing            mt-broker-controller-7778d47797-sbg2t                        1/1     Running   0          174m
knative-eventing            mt-broker-filter-857c746446-hzddr                            1/1     Running   1          174m
knative-eventing            mt-broker-ingress-685cd6b57-sz6vr                            1/1     Running   1          174m
knative-serving             activator-859796b66c-r5zsr                                   2/2     Running   2          174m
knative-serving             autoscaler-565454fb69-4kgpj                                  2/2     Running   2          174m
knative-serving             controller-dd58865b5-dlwg6                                   2/2     Running   1          174m
knative-serving             istio-webhook-68fddcc567-n7pzq                               2/2     Running   1          174m
knative-serving             networking-istio-5664b9fb9c-jlq7q                            2/2     Running   1          174m
knative-serving             webhook-6c8b54d9-nkcq8                                       2/2     Running   2          174m
kube-system                 coredns-558bd4d5db-qdl2g                                     1/1     Running   1          3h19m
kube-system                 etcd-minikube                                                1/1     Running   0          3h19m
kube-system                 kube-apiserver-minikube                                      1/1     Running   0          3h19m
kube-system                 kube-controller-manager-minikube                             1/1     Running   0          3h19m
kube-system                 kube-proxy-7qwz6                                             1/1     Running   0          3h19m
kube-system                 kube-scheduler-minikube                                      1/1     Running   0          3h19m
kube-system                 storage-provisioner                                          1/1     Running   1          3h19m
kubeflow-user-example-com   ml-pipeline-ui-artifact-767659f9df-8p8ht                     2/2     Running   0          134m
kubeflow-user-example-com   ml-pipeline-visualizationserver-6ff9f47c6b-52lpd             2/2     Running   0          134m
kubeflow                    admission-webhook-deployment-f5d8f47f8-j6spk                 1/1     Running   0          172m
kubeflow                    cache-deployer-deployment-6dbb64ddcd-sn42c                   2/2     Running   1          173m
kubeflow                    cache-server-79d58845f5-6szhs                                2/2     Running   0          173m
kubeflow                    centraldashboard-9846cbb75-d2n2c                             1/1     Running   1          172m
kubeflow                    jupyter-web-app-deployment-554975dd5d-t5jbn                  1/1     Running   0          172m
kubeflow                    katib-controller-7b98cd6865-7khbj                            1/1     Running   0          172m
kubeflow                    katib-db-manager-7f5f684dd5-rjk5z                            1/1     Running   1          172m
kubeflow                    katib-mysql-85fc9c74b8-r4j2j                                 1/1     Running   1          172m
kubeflow                    katib-ui-64fbdf4d94-kc88w                                    1/1     Running   0          172m
kubeflow                    kfserving-controller-manager-0                               2/2     Running   0          173m
kubeflow                    kubeflow-pipelines-profile-controller-596b896f8d-jjgfr       1/1     Running   0          173m
kubeflow                    metacontroller-0                                             1/1     Running   0          173m
kubeflow                    metadata-envoy-deployment-95b58bbbb-xcl2t                    1/1     Running   0          173m
kubeflow                    metadata-grpc-deployment-c8f784fdf-n8cds                     2/2     Running   3          173m
kubeflow                    metadata-writer-76b6b98985-jb8md                             2/2     Running   1          173m
kubeflow                    minio-5b65df66c9-4hjx6                                       2/2     Running   0          173m
kubeflow                    ml-pipeline-5c5d8f4959-4bb5d                                 2/2     Running   3          173m
kubeflow                    ml-pipeline-persistenceagent-6ff46967ff-k4b4s                2/2     Running   1          173m
kubeflow                    ml-pipeline-scheduledworkflow-66bdf9948d-vqdzx               2/2     Running   0          173m
kubeflow                    ml-pipeline-ui-57fdfc58cc-mdnvr                              2/2     Running   1          173m
kubeflow                    ml-pipeline-viewer-crd-64dddf4597-p9xb9                      2/2     Running   1          173m
kubeflow                    ml-pipeline-visualizationserver-77b748f8fd-vxc7s             2/2     Running   1          173m
kubeflow                    mpi-operator-d5bfb8489-2mwpr                                 1/1     Running   1          172m
kubeflow                    mxnet-operator-6cffc568b7-wd5xv                              1/1     Running   1          172m
kubeflow                    mysql-f7b9b7dd4-2pxbh                                        2/2     Running   0          173m
kubeflow                    notebook-controller-deployment-7bd85f9f7d-cdknp              1/1     Running   1          172m
kubeflow                    profiles-deployment-74b4f94d5c-skcv6                         2/2     Running   2          172m
kubeflow                    pytorch-operator-56bffbbd86-7svvr                            2/2     Running   1          172m
kubeflow                    tensorboard-controller-controller-manager-77c89cd644-hcbln   3/3     Running   3          172m
kubeflow                    tensorboards-web-app-deployment-59ff4c7bd8-7sfss             1/1     Running   0          172m
kubeflow                    tf-job-operator-859885c8c4-c7lhb                             1/1     Running   2          172m
kubeflow                    volumes-web-app-deployment-6457c9bcfc-dl5mq                  1/1     Running   0          172m
kubeflow                    workflow-controller-67bf6d848b-kczq2                         2/2     Running   2          173m
kubeflow                    xgboost-operator-deployment-c6ddb584-j7zsz                   2/2     Running   1          172m
```

모든 Pod의 Status가 Running을 확인하였습니다.
만약 Pods의 상태가 Running이 아닌 아래와 같은 상태라면 배포 요청한 컴포넌트들이 순차적으로 처리가 될 것입니다.
- Init:0/1
- PodInitializing
- ContainerCreating

그런데 **CrashLoopBackOff**이 있다면, 설정에 문제가 있거나 리소스가 부족할 수 있습니다.
Log를 확인해 봅니다.
```bash
kubectl -n [NAMESPACE] logs pods/[POD_NAME]
```

## 05. Kubeflow 대시보드 접속!
Istio Ingress Gateway를 통해 대시보드에 접속해보도록 합니다.
```bash
kubectl port-forward svc/istio-ingressgateway -n istio-system 8080:80
```

![](https://images.velog.io/images/haje/post/af181b7b-a5cb-48d8-9c13-74718e8b7776/image.png)

http://127.0.0.1:8080/

![](https://images.velog.io/images/haje/post/f3bbf791-10a5-4a37-b1ef-8770e724a2f7/image.png)


# 참고문서
- [Kubeflow Manifests](https://github.com/kubeflow/manifests)
- [Fix dex for Kubernetes 1.21 #1883](https://github.com/kubeflow/manifests/pull/1883)